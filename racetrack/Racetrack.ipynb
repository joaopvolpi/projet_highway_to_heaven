{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "import highway_env  \n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDY TO REALIZE:\n",
    "\n",
    "HYPERPARAMETERS \n",
    "TEST WITH TEACHERS ENVIROMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32),\n",
       " {'speed': 10,\n",
       "  'crashed': False,\n",
       "  'action': array([0.46991643], dtype=float32),\n",
       "  'rewards': {'lane_centering_reward': 1.0,\n",
       "   'action_reward': 0.46991643,\n",
       "   'collision_reward': False,\n",
       "   'on_road_reward': True}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"racetrack-v0\",render_mode=\"rgb_array\")\n",
    "\n",
    "config = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"OccupancyGrid\",\n",
    "        \"vehicles_count\": 10,\n",
    "        \"features\": ['presence', 'on_road'],\n",
    "        \"grid_size\": [[-18, 18], [-18, 18]],\n",
    "        \"grid_step\": [3, 3],\n",
    "        \"as_image\": False,\n",
    "        \"align_to_vehicle_axes\": True\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"type\": \"ContinuousAction\",\n",
    "        \"longitudinal\": False,\n",
    "        \"lateral\": True\n",
    "    },\n",
    "    \"simulation_frequency\": 15,\n",
    "    \"policy_frequency\": 5,\n",
    "    \"duration\": 300,\n",
    "    \"collision_reward\": -2,\n",
    "    \"lane_centering_cost\": 2,\n",
    "    \"action_reward\": -0.3,\n",
    "    \"controlled_vehicles\": 1,\n",
    "    \"other_vehicles\": 10,\n",
    "    \"screen_width\": 600,\n",
    "    \"screen_height\": 600,\n",
    "    \"centering_position\": [0.5, 0.5],\n",
    "    \"scaling\": 7,\n",
    "    \"show_trajectories\": False,\n",
    "    \"render_agent\": True,\n",
    "    \"offscreen_rendering\": False\n",
    "}\n",
    "env.unwrapped.configure(config)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma 0.6 0.8 0.99 \n",
    "lr 5e-4 and 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitoriano/anaconda3/envs/RL/lib/python3.9/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 802      |\n",
      "|    ep_rew_mean     | 24       |\n",
      "| time/              |          |\n",
      "|    fps             | 37       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 23.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012742138 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.297      |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | -0.00642    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 0.0289      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 35.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023322187 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 0.0181      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 589        |\n",
      "|    ep_rew_mean          | 44.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02147061 |\n",
      "|    clip_fraction        | 0.0544     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.897      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.00351    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0214    |\n",
      "|    std                  | 0.824      |\n",
      "|    value_loss           | 0.00546    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 481         |\n",
      "|    ep_rew_mean          | 88.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028464215 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    std                  | 0.791       |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037084006 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    std                  | 0.738       |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 289         |\n",
      "|    ep_rew_mean          | 94.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046543997 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | -0.000895   |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    std                  | 0.709       |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | 99.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042649657 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.656       |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 293         |\n",
      "|    ep_rew_mean          | 116         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 458         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050326105 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.964      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | 0.0113      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 0.61        |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 273        |\n",
      "|    ep_rew_mean          | 121        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 513        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04917502 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.889     |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0524    |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    std                  | 0.565      |\n",
      "|    value_loss           | 0.0987     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 262        |\n",
      "|    ep_rew_mean          | 124        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 570        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05854072 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.801     |\n",
      "|    explained_variance   | 0.496      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0447    |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    std                  | 0.511      |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 256         |\n",
      "|    ep_rew_mean          | 129         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059354577 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | -0.0273     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 0.475       |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 179         |\n",
      "|    ep_rew_mean          | 130         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064744875 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.629      |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | -0.0528     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    std                  | 0.432       |\n",
      "|    value_loss           | 0.073       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 170        |\n",
      "|    ep_rew_mean          | 128        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 725        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06719119 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.53      |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0197     |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.036     |\n",
      "|    std                  | 0.391      |\n",
      "|    value_loss           | 0.0975     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 189        |\n",
      "|    ep_rew_mean          | 135        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 778        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06248083 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.43      |\n",
      "|    explained_variance   | 0.928      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0092    |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    std                  | 0.354      |\n",
      "|    value_loss           | 0.0678     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 169        |\n",
      "|    ep_rew_mean          | 129        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 829        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06143727 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.324     |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0478    |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    std                  | 0.315      |\n",
      "|    value_loss           | 0.039      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 143        |\n",
      "|    ep_rew_mean          | 111        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 880        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07106463 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.225     |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0174    |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    std                  | 0.29       |\n",
      "|    value_loss           | 0.119      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 98.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082145035 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0005      |\n",
      "|    loss                 | -0.0471     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 0.0652      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 127        |\n",
      "|    ep_rew_mean          | 101        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 986        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07995134 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0697    |\n",
      "|    explained_variance   | 0.71       |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0212    |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    std                  | 0.25       |\n",
      "|    value_loss           | 0.0662     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 131        |\n",
      "|    ep_rew_mean          | 105        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 1038       |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07350144 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00788   |\n",
      "|    explained_variance   | 0.754      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0418    |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 0.0644     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 116        |\n",
      "|    ep_rew_mean          | 104        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 1090       |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07368222 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.0577     |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | 0.0158     |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    std                  | 0.22       |\n",
      "|    value_loss           | 0.059      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 117       |\n",
      "|    ep_rew_mean          | 105       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 39        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 1145      |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0984594 |\n",
      "|    clip_fraction        | 0.36      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0.13      |\n",
      "|    explained_variance   | 0.76      |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.0133   |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -0.0277   |\n",
      "|    std                  | 0.203     |\n",
      "|    value_loss           | 0.0511    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 117        |\n",
      "|    ep_rew_mean          | 106        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 1196       |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07905297 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.218      |\n",
      "|    explained_variance   | 0.756      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.0675    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    std                  | 0.184      |\n",
      "|    value_loss           | 0.053      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 114        |\n",
      "|    ep_rew_mean          | 103        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 1251       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09905751 |\n",
      "|    clip_fraction        | 0.388      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.308      |\n",
      "|    explained_variance   | 0.723      |\n",
      "|    learning_rate        | 0.0005     |\n",
      "|    loss                 | -0.013     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 0.0602     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 105       |\n",
      "|    ep_rew_mean          | 95.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 39        |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 1305      |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1014649 |\n",
      "|    clip_fraction        | 0.39      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0.373     |\n",
      "|    explained_variance   | 0.73      |\n",
      "|    learning_rate        | 0.0005    |\n",
      "|    loss                 | -0.000959 |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -0.017    |\n",
      "|    std                  | 0.162     |\n",
      "|    value_loss           | 0.0746    |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])]),\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=10,\n",
    "    learning_rate=5e-4,\n",
    "    gamma=0.8,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=int(5e4))\n",
    "model.save(\"racetrack_ppo/model\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 389      |\n",
      "|    ep_rew_mean     | 48       |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 37       |\n",
      "|    time_elapsed    | 104      |\n",
      "|    total_timesteps | 3894     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.69    |\n",
      "|    critic_loss     | 0.0029   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3793     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 333      |\n",
      "|    ep_rew_mean     | 115      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 36       |\n",
      "|    time_elapsed    | 183      |\n",
      "|    total_timesteps | 6662     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.77    |\n",
      "|    critic_loss     | 1.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6561     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 403      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 342      |\n",
      "|    total_timesteps | 12100    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -56      |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11999    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 456      |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 531      |\n",
      "|    total_timesteps | 18237    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.3    |\n",
      "|    critic_loss     | 10.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18136    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 451      |\n",
      "|    ep_rew_mean     | 149      |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 651      |\n",
      "|    total_timesteps | 22526    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.8    |\n",
      "|    critic_loss     | 14.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22425    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 456      |\n",
      "|    ep_rew_mean     | 175      |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 794      |\n",
      "|    total_timesteps | 27340    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.5    |\n",
      "|    critic_loss     | 6.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27239    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 448      |\n",
      "|    ep_rew_mean     | 181      |\n",
      "| time/              |          |\n",
      "|    episodes        | 70       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 908      |\n",
      "|    total_timesteps | 31373    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87.5    |\n",
      "|    critic_loss     | 1.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31272    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 460      |\n",
      "|    ep_rew_mean     | 199      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 1062     |\n",
      "|    total_timesteps | 36834    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.9    |\n",
      "|    critic_loss     | 5.63     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36733    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 450      |\n",
      "|    ep_rew_mean     | 201      |\n",
      "| time/              |          |\n",
      "|    episodes        | 90       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 1166     |\n",
      "|    total_timesteps | 40514    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.3    |\n",
      "|    critic_loss     | 1.33     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40413    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 467      |\n",
      "|    ep_rew_mean     | 221      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 1345     |\n",
      "|    total_timesteps | 46728    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.4    |\n",
      "|    critic_loss     | 2.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 46627    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitoriano/anaconda3/envs/RL/lib/python3.9/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'racetrack_ddpg' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.8 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=int(5e4), log_interval=10)\n",
    "model.save(\"racetrack_ddpg/model\")\n",
    "vec_env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitoriano/anaconda3/envs/RL/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.config to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.config` for environment variables or `env.get_wrapper_attr('config')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env.config[\"duration\"] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitoriano/anaconda3/envs/RL/lib/python3.9/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ppo/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ddpg/videos/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ddpg/videos/rl-video-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ddpg/videos/rl-video-episode-1.mp4\n",
      "Moviepy - Building video /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ppo/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ppo/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ppo/videos/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"racetrack_ppo/model\", env=env)\n",
    "\n",
    "env = RecordVideo(\n",
    "    env, video_folder=\"racetrack_ppo/videos\", episode_trigger=lambda e: True\n",
    ")\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "for video in range(1):\n",
    "    done = truncated = False\n",
    "    obs, info = env.reset()\n",
    "    while not (done or truncated):\n",
    "        # Predict\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        # Get reward\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # Render\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitoriano/anaconda3/envs/RL/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 2.32GB > 2.21GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ddpg/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ddpg/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/racetrack_ddpg/videos/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "model = DDPG.load(\"racetrack_ddpg/model\")\n",
    "\n",
    "env = RecordVideo(\n",
    "    env, video_folder=\"racetrack_ddpg/videos\", episode_trigger=lambda e: True\n",
    ")\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "for video in range(1):\n",
    "    done = truncated = False\n",
    "    obs, info = env.reset()\n",
    "    while not (done or truncated):\n",
    "        # Predict\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        # Get reward\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # Render\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing PPO in intersection env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitoriano/anaconda3/envs/RL/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/vitoriano/anaconda3/envs/RL/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.config to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.config` for environment variables or `env.get_wrapper_attr('config')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32),\n",
       " {'speed': 8,\n",
       "  'crashed': False,\n",
       "  'action': array([-0.52099913], dtype=float32),\n",
       "  'rewards': {'collision_reward': False,\n",
       "   'high_speed_reward': 0.0,\n",
       "   'lane_change_reward': False,\n",
       "   'on_road_reward': True}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"roundabout-v0\",render_mode=\"rgb_array\")\n",
    "env.configure({\n",
    "    \"observation\": {\n",
    "        \"type\": \"OccupancyGrid\",\n",
    "        \"vehicles_count\": 10,\n",
    "        \"features\": ['presence', 'on_road'],\n",
    "        \"grid_size\": [[-18, 18], [-18, 18]],\n",
    "        \"grid_step\": [3, 3],\n",
    "        \"as_image\": False,\n",
    "        \"align_to_vehicle_axes\": True\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"type\": \"ContinuousAction\",\n",
    "        \"longitudinal\": False,\n",
    "        \"lateral\": True\n",
    "    }\n",
    "})\n",
    "env.config[\"duration\"] = 30\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Moviepy - Building video /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/roundanbout_ppo/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/roundanbout_ppo/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/vitoriano/Documents/ws-vscode/projet_highway_to_heaven/racetrack/roundanbout_ppo/videos/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"racetrack_ppo/model\",env=env)\n",
    "\n",
    "env = RecordVideo(\n",
    "    env, video_folder=\"roundanbout_ppo/videos\", episode_trigger=lambda e: True\n",
    ")\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "for video in range(1):\n",
    "    done = truncated = False\n",
    "    obs, info = env.reset()\n",
    "    while not (done or truncated):\n",
    "        # Predict\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        # Get reward\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # Render\n",
    "        env.render()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
